{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["# ðŸ¥‰ Bronze â€” Ingest Real Pushshift JSONL\n\n**Run this first, once.** Reads your 20GB JSONL files, enforces schema, writes partitioned Parquet.\n\nPlace all your `.jsonl` files in `data/bronze/raw/` before running.\n"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName('Reddit-Bronze')\n",
    "    .master('local[2]')\n",
    "    .config('spark.driver.memory', '4g')\n",
    "    .config('spark.sql.shuffle.partitions', '8')\n",
    "    .config('spark.sql.adaptive.enabled', 'true')\n",
    "    # Pushshift files are large â€” increase max partition bytes\n",
    "    .config('spark.sql.files.maxPartitionBytes', '256m')\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark.sparkContext.setLogLevel('WARN')\n",
    "print('Spark ready:', spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pushshift schema â€” covers all fields we actually need\n",
    "# Any field not in this schema is silently dropped (saves memory)\n",
    "SCHEMA = StructType([\n",
    "    StructField('id',                StringType(),  False),\n",
    "    StructField('subreddit',         StringType(),  False),\n",
    "    StructField('author',            StringType(),  True),\n",
    "    StructField('title',             StringType(),  True),\n",
    "    StructField('selftext',          StringType(),  True),\n",
    "    StructField('score',             IntegerType(), True),\n",
    "    StructField('upvote_ratio',      DoubleType(),  True),\n",
    "    StructField('num_comments',      IntegerType(), True),\n",
    "    StructField('created_utc',       LongType(),    False),\n",
    "    StructField('url',               StringType(),  True),\n",
    "    StructField('domain',            StringType(),  True),\n",
    "    StructField('is_self',           BooleanType(), True),\n",
    "    StructField('over_18',           BooleanType(), True),\n",
    "    StructField('stickied',          BooleanType(), True),\n",
    "    StructField('locked',            BooleanType(), True),\n",
    "    StructField('removed_by_category', StringType(), True),\n",
    "    StructField('link_flair_text',   StringType(),  True),\n",
    "    StructField('total_awards_received', IntegerType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_PATH    = '../data/bronze/raw/*.jsonl'\n",
    "BRONZE_PATH = '../data/bronze/parquet'\n",
    "\n",
    "raw = (\n",
    "    spark.read\n",
    "    .schema(SCHEMA)\n",
    "    .option('mode', 'PERMISSIVE')\n",
    "    .json(RAW_PATH)\n",
    ")\n",
    "\n",
    "print('Raw count:', raw.count())\n",
    "raw.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add partition columns + clean up obvious junk\n",
    "bronze = (\n",
    "    raw\n",
    "    .filter(F.col('id').isNotNull() & F.col('subreddit').isNotNull())\n",
    "    # Remove deleted/removed posts (text is '[deleted]' or '[removed]')\n",
    "    .filter(~F.lower(F.col('selftext')).isin('[deleted]', '[removed]'))\n",
    "    .withColumn('created_ts',  F.to_timestamp(F.from_unixtime('created_utc')))\n",
    "    .withColumn('year',        F.year('created_ts').cast('string'))\n",
    "    .withColumn('month',       F.lpad(F.month('created_ts').cast('string'), 2, '0'))\n",
    "    .withColumn('subreddit',   F.lower(F.trim('subreddit')))\n",
    "    .withColumn('author',      F.lower(F.trim('author')))\n",
    "    .withColumn('ingested_at', F.current_timestamp())\n",
    "    # Combine title + selftext into one searchable text field\n",
    "    .withColumn('full_text',\n",
    "        F.concat_ws(' ',\n",
    "            F.coalesce('title', F.lit('')),\n",
    "            F.coalesce('selftext', F.lit(''))\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Show subreddit distribution\n",
    "bronze.groupBy('subreddit').count().orderBy(F.desc('count')).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Bronze â€” partition by subreddit + year\n",
    "# For 20GB, this will take 10â€“20 minutes on local\n",
    "(\n",
    "    bronze.write\n",
    "    .mode('overwrite')\n",
    "    .partitionBy('subreddit', 'year')\n",
    "    .parquet(BRONZE_PATH)\n",
    ")\n",
    "print('Bronze done âœ“')\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.10.0"}},
 "nbformat": 4,
 "nbformat_minor": 4
}
